[INCLUDE=presentation]
Title         : Mapping Pleiotropic Effects
Author        : Diogo Melo
Email         : diogro@gmail.com
Reveal Theme  : solarized
Beamer Theme  : singapore
Package       : amsmath
Package       : setspace
Package       : mathptmx
Package       : stackengine
Package       : url
Transition    : linear
Locale        : pt_br


~ MathDefs 
\parskip 1em
\newcommand\stackequal[2]{%
  \mathrel{\stackunder[2pt]{\stackon[4pt]{=}{$\scriptscriptstyle#1$}}{%
  $\scriptscriptstyle#2$}}}
\def\useanchorwidth{F}
\def\mmh{{\hbox{-}}}
~ 

<script>
revealConfig.transition='linear';
</script>

[TITLE]

# Mapping pleiotropic effects

- Basic QTL mapping models
- Multivariate mapping models
- Penalized models
- Genetic effects and genetic covariance

# Experimental cross

~ Center
![](images/f2pop.png)
~

# Experimental cross

~ Center
![](images/f2popQtl.png)
~
# QTLs via Anova

~ Center
![](images/anova_plot.png)
~
# Orthogonal genetic effects

![](images/centered_anova_plot.png)

# Regression model

~ Center
![](images/ortogonal_regression_plot.png)
~

# Basic Regression

- For marker $j$ 

~ Math
\begin{aligned}
y_i &\sim Normal(E[y_i], R) \\
E[y_i] &= \mu + a_j X_{ij}^a + d_j X_{ij}^d \\
X_{ij}^{a} &\in 
\begin{bmatrix} 
  1 & 0 & -1 
\end{bmatrix} \\
X_{ij}^{d} &\in 
\begin{bmatrix} 
  1 & 0
\end{bmatrix}
\end{aligned}
~

# Using significance of each marker

~ Center
![](images/LPR_f2.png)
~

# LD can be a problem

~ Center
![](images/multiQTL_reg.png)
~

# Interval mapping

Include flanking markers

~ Math
\begin{aligned}
E[y_i] = & \mu + a_j X_{ij}^{a} + d_j X_{ij}^{d} + \\
&+ a_{j-1} X_{ij-1}^{a} + d_{j-1} X_{ij-1}^{d} + \\
&+ a_{j+1} X_{ij+1}^{a} + d_{j+1} X_{ij+1}^{d}
\end{aligned}
~

# Interval mapping allows for more precise mapping

~ Center
![](images/multiQTL_int.png)
~

# Advanced Intercross Lines (AIL) and mapping resolution

~ Center
![](images/f3pop.png)
~

# AIL (or outbred populations)

~ Center
![](images/crosses.png){ width:700px }
~

# Mixed models can account for population structure

- For an individual in family $k$

~ Math
E[y_i] = \mu + \beta_{k[i]} +
a_j X_{ij}^a +
d_j X_{ij}^d 
~

~ Math
  \beta_k \sim Normal(0, G)
~

- {.fragment} Same thing can be applied for interval mapping
- {.fragment} Works, but is slow
- {.fragment} Approximations: EMMA, EMMAx, GEMMA, GAPIT, FaST-LMM...

# Growth as a multivariate trait

![](images/growth_LG_SM.png)

# Growth in the F3

![](images/growth_LG_SM_F3.png)

# Covariation in growth 

![](images/growth_LG_SM_F3_covF3.png)

# Mapping growth in the F3 from the LG/SM cross

![](images/fig2_growth_manhattan.png)

# Pleiotropic effects

![](images/fig3_growth_pleiotropic_partition_ad_dm.png)

# Genetic effects PCA

![](images/fig3_growth_pleiotropic_partition_ad_dm_PCA.png)

# ancestral predictions using only F3

![](images/growth_multiple_regression_ancestral_prediction_QTL.png)

# Large models

- Can we fit all markers at once?

~ Math
E[y_i] = \mu + \sum_{j=1}^p a_j X_{ij}^a + d_j X_{ij}^d
~

- {.fragment} High correlation between markers is a problem
- {.fragment} Lots of noise and over-fitting

# megalomaniac models

~Center
![](images/mega_ML_fit.png){ width:300px }
~

# Penalized models

- Large class of models that assume most effects are zero.

- {.fragment} The LASSO (least absolute shrinkage and selection operator)
- {.fragment} Ridge Regression (less aggressive than LASSO)
- {.fragment} Elastic net regularization (mixture of LASSO and RR)


# Maximum likelihood notation

~ Math
E[y_i] = \mu + \sum_{j=1}^p a_j X_{ij}^a
~

~ Math {.fragment}
    (\hat \mu, \{\hat a_j\}_{j=1}^p) \stackequal{}{argmin} \left \{ \sum_{i = 1}^n \left ( y_i - \mu - \sum_{j = 1}^p a_j X_{ij}^a \right )^2 \right \}
~ 

# Lasso

~ Math
    (\hat \mu, \{\hat a_j\}_{j=1}^p) \stackequal{}{argmin} \left \{ \sum_{i = 1}^n \left ( y_i - \mu - \sum_{j = 1}^p a_j X_{ij}^a \right )^2  
    +  \lambda \sum_{j=1}^p \|a_j\| \right \}
~ 

# Ridge regression

~ Math
    (\hat \mu, \{\hat a_j\}_{j=1}^p) \stackequal{}{argmin} \left \{ \sum_{i = 1}^N \left ( y_i - \mu - \sum_{j = 1}^p a_j X_{ij}^a \right )^2  
    +  \lambda \sum_{j=1}^p \|a_j\|^2 \right \}
~ 

# Lasso e Ridge estimator

~ Center
![](images/lasso_ridge.png)
~

# LASSO is nice, but...

- No objective mapping method
- Chooses arbitrary non-zero coefficient among correlated markers
- All estimates have some shrinkage

# Lasso and shrinkage

~ Center
![](images/lasso_shrink.png)
~

# How to estimate effects precisely and use shrinkage where needed?


# Penalized hierarchical models$^2$

- don't panic

- {.fragment} Obvious Bayesian solution: add a per-coefficient shrinkage parameter

~ Center
Golden rule: "If you have a complicated problem, maybe making it more complicated will help." 
{.fragment; width: 18em; border: solid 1px black; \
  padding: 1ex; background-color: FloralWhite }
~


# Penalized hierarchical models

- General idea:

~ Math
E[y_i] = \mu + \sum_{j=1}^N a_j X_{ij}^a
~ 

~ Math
\begin{aligned}
&P(a_j|\lambda_j) \\
&P(\lambda_j|\tau) \\
&P(\tau)
\end{aligned} 
~

# Hierarchical adaptive lasso (HAL)

~ Math
\begin{aligned}
P(a_j|\lambda_j) &= Normal(0, \lambda_j^2) \\
P(\lambda_j|\tau) &= Gamma(1, \tau^2/2) \\
P(\tau) &= Inv\mmh Gamma(a, b)
\end{aligned} 
~

~Center
- $\lambda_j \rightarrow$ shrinkage local
- $\tau\rightarrow$ shrinkage global
~

# Lasso vs HAL

~ Center
![](images/lasso_HAL_shrink.png)
~

# The Horseshoe

~ Center
![](images/horseshoe.png){ width: 200px }
~

~ Begin Columns
~ Column
~~ Math
\begin{aligned}
P(a_j|\lambda_j) &= Normal(0, \lambda_j^2) \\
P(\lambda_j|\tau) &= Cauchy(0, \tau) \\
P(\tau) &= Cauchy(0, b) 
\end{aligned} 
~~
~
~ Column
- $\lambda_j \rightarrow$  local shrinkage
- $\tau\rightarrow$  global shrinkage
~
~ End Columns


# Horseshoe 

- Effect estimates have the form:

~ Math
\begin{aligned}
\hat a_j^{HS} &= w_j\hat a_j^{ML} \\
P(w_j) &= Beta(0.5, 0.5)
\end{aligned} 
~

~Center
$w_j$ is a shrinkage intensity measure, or, an __inclusion parameter__
{.fragment; width: 18em; border: solid 1px black; \
  padding: 1ex; background-color: FloralWhite }
~

# Prior of the shrinkage intensity

~ Center
![](images/beta_dist.png){ width:600px }
~

# Penalized hierarchical model mapping

~ Center
![](images/all_fits.png)
~

# HS mapping on the growth traits

![](images/fig5_growth_pleiotropic_partition_ad_dm_GP.png)

# ancestral predictions with HS

![](images/growth_multiple_regression_ancestral_prediction_full_genome.png)

# Linking pleiotropic effects with variation

~ Math
\text{Average effect:}  \alpha_{j} = a_{j} + \left\lbrack q_{j} - p_{j} \right\rbrack \circ d_{j}
~

~ Math
G_{kk} = \sum_{j=1}^n 2p_{j}q_{j}\alpha_{j(k)}^{2} + \sum_{j=1}^n \sum_{x=1}^n \left\lbrack {2D_{jx}\alpha}_{j(k)}\alpha_{x(k)} \right\rbrack_{j \neq x}
~

# Linking pleiotropic effects with covariation

~ Math
G_{kl} = \sum_{j=1}^n 2p_{j}q_{j}\alpha_{j(k)}\alpha_{j(l)} + \sum_{j=1}^n \sum_{x=1}^n \left\lbrack {2 D_{jx}\alpha}_{j(k)}\alpha_{x(l)} \right\rbrack_{j \neq x}
~

# Additive and Dominance correlations

![](images/growth_cov_prediction_QTL.png)

# Additive and Dominance correlations

![](images/growth_cov_prediction_QTL_regression.png)